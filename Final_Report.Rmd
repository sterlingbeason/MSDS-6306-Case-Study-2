---
title: 'Case Study 2: Final Report'
author: "Sterling Beason"
date: "12/5/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(GGally)
library(ggplot2)
library(corrplot)
library(Hmisc)
library(randomForest)
library(earth) # identify predictors
library(class)
library(caret)
library(e1071)
library(Metrics) # rsme
```

## Executive Summary
DDSAnalytics is an analytics company that specializes in talent management solututions for Fortune 100 companies. Frito Lay has contracted DDSAnalytics to analyze and build models for employee attrition and monthly income (salary). It is our privilege to present our findings to the CEO and CFO of Frito Lay.
The dataset provided by your company included 870 observations with 36 features. We constructed models to best predict attrition and monthly income with several different industry standard algorithms: naive Bayes, kNN, and multiple linear regression. Using multiple feature selection techniques; such as, Random Forest, Multivariate Adaptive Regression (MARS), and step-wize regression.

Top Three Predictors for Attrition: [see visuals](#identify-top-three-attrition-predictors)

* Overtime

* Years With Current Manager

* Age

Our best model for attrition utilized the naive Bayes algorithm with all predictors. With this model, we achieved an accuracy of ~84%, sensitivity of nearly 90%, and a specificity greater than 60%. [see more](#naive-bayes---all-predictors-(best))

Top Three Predictors for Monthly Income: [see visuals](#top-three-salary-predictors)

* Job Level

* Job Role

* Total Working Years

With a root mean square deviation (RSME) of less than $1k, our best model utilized multiple linear regression using the top three predictors we identified. [see more](#top-three-features---mlr-(best))

Along with this report, we are pleased to provide back our attrition and salary predictions for the non-labeled datasets "CaseStudy2CompSet No Attrition.csv" and "CaseStudy2CompSet No Salary.csv". You can find these now labeled dataset files in the "prediction" folder accompanied by this report.

## Dataset
**CaseStudy2-data.csv**

870 observations, 36 features

| Name | - | Used |
|-|-|-|
| Age |  | yes |
| Attrition |  | yes |
| BusinessTravel |  | yes |
| DailyRate |  | yes |
| Department |  | yes |
| DistanceFromHome |  | yes |
| Education |  | yes |
| EducationField |  | yes |
| EmployeeNumber |  | no |
| EnvironmentSatisfaction |  | yes |
| Gender |  | yes |
| HourlyRate |  | yes |
| ID |  | no |
| JobInvolvement |  | yes |
| JobLevel |  | yes |
| JobRole |  | yes |
| JobSatisfaction |  | yes |
| MaritalStatus |  | yes |
| MonthlyIncome |  | yes |
| MonthlyRate |  | yes |
| NumCompaniesWorked |  | yes |
| Over18 |  | no |
| OverTime |  | yes |
| PercentSalaryHike |  | yes |
| PerformanceRating |  | yes |
| RelationshipSatisfaction |  | yes |
| StandardHours |  | no |
| StockOptionLevel |  | yes |
| TotalWorkingYears |  | yes |
| TrainingTimesLastYear |  | yes |
| WorkLifeBalance |  | yes |
| YearsAtCompany |  | yes |
| YearsInCurrentRole |  | yes |
| YearsSinceLastPromotion |  | yes |
| YearsWithCurrManager |  | yes |


## Exploratory Data Analysis (EDA)
```{r}
# import data
dataRaw = read.csv('./data/CaseStudy2-data.csv', header = TRUE)

# Remove columns
# Non-informative columns: ID, EmployeeNumber
# Useless columns with one value: EmployeeCount, Over18, StandardHours
data = dataRaw %>% select(-c('ID', 'EmployeeNumber', 'EmployeeCount', 'Over18', 'StandardHours'))

# convert factors that were picked up as int
data$EnvironmentSatisfaction <- factor(data$EnvironmentSatisfaction)
data$JobInvolvement <- factor(data$JobInvolvement)
data$JobLevel <- factor(data$JobLevel)
data$JobSatisfaction <- factor(data$JobSatisfaction)
data$PerformanceRating <- factor(data$PerformanceRating)
data$RelationshipSatisfaction <- factor(data$RelationshipSatisfaction)
data$WorkLifeBalance <- factor(data$WorkLifeBalance)
data$StockOptionLevel <- factor(data$StockOptionLevel)

# Create split copy of data by factor and numeric
categoricalCols = data %>% select_if(is.factor)
continuousCols = data %>% select_if(is.numeric)
```

### Visualize Numeric Correlations
```{r}
continuousCols.cor = cor(continuousCols)
corrplot(continuousCols.cor)
```

## Attrition Modeling

### Identify Top Three Attrition Predictors
#### Within All Predictors
```{r}
mars <- earth(Attrition ~ ., data = data)
evimp <- evimp(mars)

evimp[1:3, c(3,4,6)]
```

#### Within Numeric Predictors
```{r, message = F}
continuousColsWAttrition = continuousCols
continuousColsWAttrition$Attrition <- data$Attrition

mars <- earth(Attrition ~ ., data = continuousColsWAttrition)
evimp <- evimp(mars)

evimp[1:3, c(3,4,6)]

data %>% select('TotalWorkingYears', 'NumCompaniesWorked', 'YearsSinceLastPromotion', 'Attrition') %>% ggpairs(mapping = ggplot2::aes(colour=Attrition))
```

### Data Partitioning (Train/Test)
```{r}
# split data into training and testing
trainInd = createDataPartition(data$Attrition, times = 1, p = 0.7, list = FALSE)

train = data[trainInd,]
test = data[-trainInd,]
```

### Naive Bayes - All Predictors (Best)
```{r}
# Naive Bayes model
model <- naiveBayes(Attrition ~ ., data = train)

# Make predictions
pred <- predict(model, test)

# Confusion Matrix
confusionMatrix(table(pred, test$Attrition))
```

```{r, include=FALSE}
# import non-labeled dataset and export predictions
attritionNonLabeled = read.csv('./data/CaseStudy2CompSet No Attrition.csv', header = TRUE)

# convert factors that were picked up as int
attritionNonLabeled$EnvironmentSatisfaction <- factor(attritionNonLabeled$EnvironmentSatisfaction)
attritionNonLabeled$JobInvolvement <- factor(attritionNonLabeled$JobInvolvement)
attritionNonLabeled$JobLevel <- factor(attritionNonLabeled$JobLevel)
attritionNonLabeled$JobSatisfaction <- factor(attritionNonLabeled$JobSatisfaction)
attritionNonLabeled$PerformanceRating <- factor(attritionNonLabeled$PerformanceRating)
attritionNonLabeled$RelationshipSatisfaction <- factor(attritionNonLabeled$RelationshipSatisfaction)
attritionNonLabeled$WorkLifeBalance <- factor(attritionNonLabeled$WorkLifeBalance)
attritionNonLabeled$StockOptionLevel <- factor(attritionNonLabeled$StockOptionLevel)

# Make predictions
attritionPredictions <- predict(model, attritionNonLabeled)

# merge predictions
attritionNonLabeled$Attrition <- attritionPredictions

# Write CSV
write.csv(attritionNonLabeled, file = "./predictions/Attrition_Predictions.csv")
```

### kNN - Numeric Predictors (Worst)
k = 8 was determined as the best k value after running the kNN algorithm for 500 iterations between 1-30.
```{r}
# Filter data for numeric columns
trainNum <- train %>% select_if(is.numeric)
testNum <- test %>% select_if(is.numeric)

# Append 'Attrition' column
trainNum$Attrition <- train$Attrition
testNum$Attrition <- test$Attrition

# Run the algorithm
knn <- knn(trainNum[,1:15], testNum[,1:15], trainNum$Attrition, prob = TRUE, k = 8)
# Confusion Matrix
confusionMatrix(table(knn, testNum$Attrition))
```


## Salary (MonthlyIncome) Modeling

### Monthly Income Histogram
```{r}
hist(data$MonthlyIncome)
```

### Top Three Salary Predictors
```{r}
#data %>% select('MonthlyIncome', 'JobLevel', 'JobRole', 'TotalWorkingYears') %>% ggpairs(mapping = ggplot2::aes(colour=MonthlyIncome))
require(gridExtra)
# JobLevel
plot1 <- qplot(data$JobLevel, data$MonthlyIncome, data=data, colour=MonthlyIncome) + scale_colour_gradient(low="red", high="blue") + theme(legend.position="none")
# JobRole
plot2 <- qplot(data$JobRole, data$MonthlyIncome, data=data, colour=MonthlyIncome) + scale_colour_gradient(low="red", high="blue") + theme(legend.position="none")
# TotalWorkingYears
plot3 <- qplot(data$TotalWorkingYears, data$MonthlyIncome, data=data, colour=MonthlyIncome) + scale_colour_gradient(low="red", high="blue")

# plot columns
grid.arrange(plot1, plot2, plot3, ncol=2)
```

### Multiple Linear Regression

#### Step-wise Regression - Feature Selection
```{r}
# Adapted Source: http://r-statistics.co/Variable-Selection-and-Importance-With-R.html

base.mod <- lm(MonthlyIncome ~ 1 , data= data)  # base intercept only model
all.mod <- lm(MonthlyIncome ~ . , data= data) # full model with all predictors
stepMod <- step(base.mod, scope = list(lower = base.mod, upper = all.mod), direction = "both", trace = 0, steps = 1000)  # perform step-wise algorithm
shortlistedVars <- names(unlist(stepMod[[1]])) # get the shortlisted variable.
shortlistedVars <- shortlistedVars[!shortlistedVars %in% "(Intercept)"]  # remove intercept 
print(shortlistedVars)
```

#### Top Three Features - MLR (Best)
```{r}
# The three predictors varified from step-wise algo.
model2 <- lm(MonthlyIncome ~ JobLevel + JobRole + TotalWorkingYears, data = train)

summary(model2)

# residual histogram
hist(model2$residuals, col = "blue", main = "Histogram of Residuals")
plot(model2$fitted.values,model2$residuals, main = "Plot of Residuals v. Fitted Values")
abline(a=0, b=0)

# Make predictions
model2.fit <- predict(model2, newdata = test)

# Plot actual vs predicted
plot(model2.fit,test$MonthlyIncome, xlab="predicted", ylab="actual")
abline(a=0,b=1)

#RSME from Metrics:: (https://www.rdocumentation.org/packages/Metrics/versions/0.1.4/topics/rmse)
rmse(test$MonthlyIncome, model2.fit)
```

```{r, include=FALSE}
# import non-labeled dataset and export predictions
salaryNonLabeled = read.csv('./data/CaseStudy2CompSet No Salary.csv', header = TRUE)

# convert factors that were picked up as int
salaryNonLabeled$EnvironmentSatisfaction <- factor(salaryNonLabeled$EnvironmentSatisfaction)
salaryNonLabeled$JobInvolvement <- factor(salaryNonLabeled$JobInvolvement)
salaryNonLabeled$JobLevel <- factor(salaryNonLabeled$JobLevel)
salaryNonLabeled$JobSatisfaction <- factor(salaryNonLabeled$JobSatisfaction)
salaryNonLabeled$PerformanceRating <- factor(salaryNonLabeled$PerformanceRating)
salaryNonLabeled$RelationshipSatisfaction <- factor(salaryNonLabeled$RelationshipSatisfaction)
salaryNonLabeled$WorkLifeBalance <- factor(salaryNonLabeled$WorkLifeBalance)
salaryNonLabeled$StockOptionLevel <- factor(salaryNonLabeled$StockOptionLevel)

# Make predictions
salaryPredictions <- predict(model2, newdata = salaryNonLabeled)

# merge predictions
salaryNonLabeled$MonthlyIncome <- salaryPredictions

# Write CSV
write.csv(salaryNonLabeled, file = "./predictions/Salary_Predictions.csv")
```

#### All Features - MLR (Worst)
```{r}
# MLR with all predictors used
model <- lm(MonthlyIncome ~ ., data = train)

summary(model)

# test predictions
model.fit <- predict(model, newdata = test)

# RSME
rmse(test$MonthlyIncome, model.fit)
```